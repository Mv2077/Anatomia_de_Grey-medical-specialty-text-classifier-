{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mv2077/Anatomia_de_Grey-medical-specialty-text-classifier-/blob/main/Anatomia_de_Grey(2_0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Medical cases classification"
      ],
      "metadata": {
        "id": "6dhn1cU1BOiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "l1YGD5q3CYdd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.30.0 peft==0.5.0 --upgrade"
      ],
      "metadata": {
        "id": "xqMmSJt-_Xlr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "VRVvxxA5_ZNr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "5YGG8k4u_WiY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas"
      ],
      "metadata": {
        "id": "xpI9lwdZ_bg7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W-Wu_CU8gKJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial\n",
        "\n"
      ],
      "metadata": {
        "id": "-cbPN0xJBMLj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datasets import Dataset\n",
        "import tensorflow as tf\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "from transformers import EarlyStoppingCallback\n",
        "from torch.utils.data import DataLoader\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import streamlit as st\n",
        "from sklearn.utils import resample\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "from evaluate import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "71sCNmsxLGk0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_train.csv\"\n",
        "test_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_test.csv\"\n",
        "validation_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_validation.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_url)\n",
        "df_test = pd.read_csv(test_url)\n",
        "df_validation = pd.read_csv(validation_url)\n",
        "\n",
        "print(df_train.head())\n"
      ],
      "metadata": {
        "id": "fq1ONuP9CN0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Business Understanding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9cvCoVKBJ41c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective:\n",
        "# Classify medical cases based on textual descriptions.\n",
        "# This helps support medical decision-making or automate triage processes.\n",
        "\n",
        "print(\"Goal: Predict the medical category of a case from its description.\")\n",
        "df_train.info()\n",
        "df_train.head()\n"
      ],
      "metadata": {
        "id": "dKhV-k-LJ8eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data understanding"
      ],
      "metadata": {
        "id": "npMqsDgRKtN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.columns)\n"
      ],
      "metadata": {
        "id": "EAJApxrtLuFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Set Info:\")\n",
        "print(df_train.info())\n",
        "print(\"\\nSample Rows:\")\n",
        "print(df_train.sample(5))\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df_train.isnull().sum())\n",
        "\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df_train['medical_specialty'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(y='medical_specialty', data=df_train, order=df_train['medical_specialty'].value_counts().index, palette='viridis')\n",
        "plt.title(\"Distribution of Medical Specialties in Training Set\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Medical Specialty\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_train['text_length'] = df_train['transcription'].apply(len)\n",
        "\n",
        "print(\"\\nText Length Statistics:\")\n",
        "print(df_train['text_length'].describe())\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df_train['text_length'], bins=30, kde=True, color='skyblue')\n",
        "plt.title(\"Distribution of Transcription Lengths\")\n",
        "plt.xlabel(\"Number of Characters\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dPe5YuzSK1V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "ecxzbtMzMH_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df_train['label'] = label_encoder.fit_transform(df_train['medical_specialty'])\n",
        "df_test['label'] = label_encoder.transform(df_test['medical_specialty'])"
      ],
      "metadata": {
        "id": "i7uF1f4LOdCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "df_train['description_clean'] = df_train['description'].apply(clean_text)\n",
        "df_test['description_clean'] = df_test['description'].apply(clean_text)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['label'] = label_encoder.fit_transform(df_train['medical_specialty'])\n",
        "df_test['label'] = label_encoder.transform(df_test['medical_specialty'])\n",
        "\n",
        "\n",
        "print(\"\\nExemplo de transcri√ß√£o limpa:\")\n",
        "print(df_train['transcription_clean'].iloc[0])\n",
        "print(\"\\nLabel original:\", df_train['medical_specialty'].iloc[0])\n",
        "print(\"Label codificado:\", df_train['label'].iloc[0])\n",
        "\n",
        "\n",
        "print(\"\\nDistribui√ß√£o de labels (treino):\")\n",
        "print(df_train['medical_specialty'].value_counts())\n"
      ],
      "metadata": {
        "id": "4PqkP2PyOfun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "train_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_train.csv\"\n",
        "test_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_test.csv\"\n",
        "validation_url = \"https://huggingface.co/datasets/hpe-ai/medical-cases-classification-tutorial/resolve/main/medical_cases_validation.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_url)\n",
        "df_test = pd.read_csv(test_url)\n",
        "df_validation = pd.read_csv(validation_url)\n",
        "\n",
        "df = pd.concat([df_train, df_test, df_validation], ignore_index=True)\n",
        "\n",
        "df = df.dropna(subset=[\"description\", \"medical_specialty\"])\n",
        "df[\"description_clean\"] = df[\"description\"].apply(clean_text)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"medical_specialty\"])\n",
        "\n",
        "print(\"\\nDistribui√ß√£o original das classes:\")\n",
        "print(df[\"medical_specialty\"].value_counts())\n",
        "\n",
        "X = df[\"description_clean\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler # Import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X.values.reshape(-1, 1), y)\n",
        "\n",
        "df_balanced = pd.DataFrame({\n",
        "    \"description_clean\": X_resampled.flatten(),\n",
        "    \"label\": y_resampled\n",
        "})\n",
        "\n",
        "\n",
        "df_balanced[\"medical_specialty\"] = label_encoder.inverse_transform(df_balanced[\"label\"])\n",
        "\n",
        "df_train, df_test = train_test_split(\n",
        "    df_balanced,\n",
        "    test_size=0.2,\n",
        "    stratify=df_balanced[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Split final realizado.\")\n",
        "print(\"Distribui√ß√£o no treino:\")\n",
        "print(df_train[\"medical_specialty\"].value_counts())"
      ],
      "metadata": {
        "id": "33lI1K_jqmRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling"
      ],
      "metadata": {
        "id": "idYQKCRxXojI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELING com Linear Regression\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(df_train['description_clean'])\n",
        "X_test = vectorizer.transform(df_test['description_clean'])\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, df_train['label'])\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(df_test['label'], y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": "mq0qLJTwXswW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(clf, 'logistic_regression_model.pkl')\n",
        "print(\"Logistic Regression model saved as 'logistic_regression_model.pkl'\")"
      ],
      "metadata": {
        "id": "bwwcF0lFOt_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling com Naive Bayes\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_train[\"description_clean\"],\n",
        "    df_train[\"label\"],\n",
        "    test_size=0.1,\n",
        "    stratify=df_train[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "nb_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\"),\n",
        "    MultinomialNB()\n",
        ")\n",
        "\n",
        "nb_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb_pipeline.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "SzwK7b37Aqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(nb_pipeline, 'naive_bayes_pipeline.pkl')\n",
        "print(\"Naive Bayes pipeline saved as 'naive_bayes_pipeline.pkl'\")"
      ],
      "metadata": {
        "id": "3fcTuGjKPPa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modeling com GPT-2\n",
        "\n",
        "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
        "\n",
        "\n",
        "def tokenize_gpt2(example):\n",
        "    return tokenizer_gpt2(\n",
        "        example[\"description_clean\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_train[\"description_clean\"].tolist(),\n",
        "    df_train[\"label\"].tolist(),\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=df_train[\"label\"]\n",
        ")\n",
        "\n",
        "train_dataset = Dataset.from_dict({\n",
        "    \"description_clean\": train_texts,\n",
        "    \"label\": train_labels\n",
        "})\n",
        "val_dataset = Dataset.from_dict({\n",
        "    \"description_clean\": val_texts,\n",
        "    \"label\": val_labels\n",
        "})\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_gpt2, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_gpt2, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "config = GPT2Config.from_pretrained(\"gpt2\", num_labels=df_train[\"label\"].nunique())\n",
        "config.pad_token_id = tokenizer_gpt2.pad_token_id\n",
        "model_gpt2 = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", config=config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./modelo_gpt2\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    logging_dir=\"./logs_gpt2\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=1.5e-5\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_gpt2,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "dbPQDbPD5YGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gpt2.save_pretrained(\"./gpt2_model\")\n",
        "tokenizer_gpt2.save_pretrained(\"./gpt2_model\")\n",
        "print(\"GPT-2 model and tokenizer saved in './gpt2_model'\")"
      ],
      "metadata": {
        "id": "LesygVkhPcoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling Distilbert\n",
        "\n",
        "train_dataset = Dataset.from_pandas(df_train[['description_clean', 'label']])\n",
        "test_dataset = Dataset.from_pandas(df_test[['description_clean', 'label']])\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['description_clean'], truncation=True)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"description_clean\"])\n",
        "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "test_dataset = test_dataset.remove_columns([\"description_clean\"])\n",
        "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=len(label_encoder.classes_)\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "DKxPuHLJ4eGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset.from_pandas(df_test[['description_clean', 'label']])\n",
        "\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_test = tokenized_test.remove_columns([\"description_clean\"])\n",
        "\n",
        "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ],
      "metadata": {
        "id": "hFPc-jSo8kGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./distilbert_model\")\n",
        "tokenizer.save_pretrained(\"./distilbert_model\")\n",
        "print(\"DistilBERT model and tokenizer saved in './distilbert_model'\")"
      ],
      "metadata": {
        "id": "_HLLsOjsQ2_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling com ModernBert\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df_train['description_clean'].tolist(),\n",
        "    df_train['label'].tolist(),\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=df_train['label']\n",
        ")\n",
        "\n",
        "train_ds = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
        "val_ds   = Dataset.from_dict({'text': val_texts,   'label': val_labels})\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
        "val_ds   = val_ds.map(tokenize_fn, batched=True)\n",
        "\n",
        "train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_ds.set_format(type=\"torch\",   columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "\n",
        "num_labels = df_train['label'].nunique()\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./modelo\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "\n",
        "accuracy = load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return accuracy.compute(predictions=preds, references=labels)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LB-LtTfPnL4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"description_clean\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "test_dataset = Dataset.from_pandas(df_test[['description_clean', 'label']])\n",
        "\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_test = tokenized_test.remove_columns([\"description_clean\"])\n",
        "\n",
        "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
        "\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ],
      "metadata": {
        "id": "zaldyUXXSjDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./modernbert_model\")\n",
        "tokenizer.save_pretrained(\"./modernbert_model\")\n",
        "print(\"ModernBert model and tokenizer saved in './modernbert_model'\")"
      ],
      "metadata": {
        "id": "z_wy6fJMRm3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation\n"
      ],
      "metadata": {
        "id": "ytVx4LXsX-Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation for Logistic Regression ---\n",
        "print(\"--- Evaluating Logistic Regression ---\")\n",
        "try:\n",
        "    loaded_lr_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "    X_test_lr = vectorizer.transform(df_test['description_clean'])\n",
        "\n",
        "    y_pred_lr = loaded_lr_model.predict(X_test_lr)\n",
        "    print(classification_report(df_test['label'], y_pred_lr, target_names=label_encoder.classes_))\n",
        "except FileNotFoundError:\n",
        "    print(\"Logistic Regression model file not found.\")\n",
        "except NameError:\n",
        "    print(\"vectorizer, df_test, or label_encoder not found. Please run the previous data preparation and modeling cells.\")\n",
        "\n",
        "# --- Evaluation for Naive Bayes ---\n",
        "print(\"\\n--- Evaluating Naive Bayes ---\")\n",
        "try:\n",
        "    loaded_nb_pipeline = joblib.load('naive_bayes_pipeline.pkl')\n",
        "    y_pred_nb = loaded_nb_pipeline.predict(df_test['description_clean'])\n",
        "    print(classification_report(df_test['label'], y_pred_nb, target_names=label_encoder.classes_))\n",
        "except FileNotFoundError:\n",
        "    print(\"Naive Bayes pipeline file not found.\")\n",
        "except NameError:\n",
        "    print(\"df_test or label_encoder not found. Please run the previous data preparation and modeling cells.\")\n",
        "\n",
        "\n",
        "# --- Evaluation for GPT-2 ---\n",
        "print(\"\\n--- Evaluating GPT-2 ---\")\n",
        "try:\n",
        "    loaded_gpt2_model = AutoModelForSequenceClassification.from_pretrained(\"./gpt2_model\")\n",
        "    loaded_gpt2_tokenizer = AutoTokenizer.from_pretrained(\"./gpt2_model\")\n",
        "    loaded_gpt2_model.eval()\n",
        "\n",
        "    gpt2_test_loader = DataLoader(tokenized_test, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "    all_preds_gpt2 = []\n",
        "    all_labels_gpt2 = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loaded_gpt2_model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in gpt2_test_loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = loaded_gpt2_model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds_gpt2.extend(preds.cpu().numpy())\n",
        "            all_labels_gpt2.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(classification_report(all_labels_gpt2, all_preds_gpt2, target_names=label_encoder.classes_))\n",
        "except FileNotFoundError:\n",
        "    print(\"GPT-2 model files not found.\")\n",
        "except NameError:\n",
        "     print(\"tokenized_test, data_collator, or label_encoder not found. Please run the previous data preparation and modeling cells.\")\n",
        "\n",
        "\n",
        "# --- Evaluation for DistilBERT ---\n",
        "print(\"\\n--- Evaluating DistilBERT ---\")\n",
        "try:\n",
        "    loaded_distilbert_model = AutoModelForSequenceClassification.from_pretrained(\"./distilbert_model\")\n",
        "    loaded_distilbert_tokenizer = AutoTokenizer.from_pretrained(\"./distilbert_model\")\n",
        "    loaded_distilbert_model.eval()\n",
        "\n",
        "\n",
        "    distilbert_test_loader = DataLoader(tokenized_test, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "    all_preds_distilbert = []\n",
        "    all_labels_distilbert = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loaded_distilbert_model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in distilbert_test_loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = loaded_distilbert_model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds_distilbert.extend(preds.cpu().numpy())\n",
        "            all_labels_distilbert.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(classification_report(all_labels_distilbert, all_preds_distilbert, target_names=label_encoder.classes_))\n",
        "except FileNotFoundError:\n",
        "    print(\"DistilBERT model files not found.\")\n",
        "except NameError:\n",
        "     print(\"tokenized_test, data_collator, or label_encoder not found. Please run the previous data preparation and modeling cells.\")\n",
        "\n",
        "\n",
        "# --- Evaluation for ModernBert ---\n",
        "print(\"\\n--- Evaluating ModernBert ---\")\n",
        "try:\n",
        "    loaded_modernbert_model = AutoModelForSequenceClassification.from_pretrained(\"./modernbert_model\")\n",
        "    loaded_modernbert_tokenizer = AutoTokenizer.from_pretrained(\"./modernbert_model\")\n",
        "    loaded_modernbert_model.eval()\n",
        "\n",
        "\n",
        "    modernbert_test_loader = DataLoader(tokenized_test, batch_size=16, collate_fn=data_collator)\n",
        "\n",
        "    all_preds_modernbert = []\n",
        "    all_labels_modernbert = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loaded_modernbert_model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in modernbert_test_loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = loaded_modernbert_model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds_modernbert.extend(preds.cpu().numpy())\n",
        "            all_labels_modernbert.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(classification_report(all_labels_modernbert, all_preds_modernbert, target_names=label_encoder.classes_))\n",
        "except FileNotFoundError:\n",
        "    print(\"ModernBert model files not found.\")\n",
        "except NameError:\n",
        "     print(\"tokenized_test, data_collator, or label_encoder not found. Please run the previous data preparation and modeling cells.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during ModernBert evaluation: {e}\")"
      ],
      "metadata": {
        "id": "jMFC1FbA7_xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deployment"
      ],
      "metadata": {
        "id": "OCao5abr0XpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2uDsyoIapgKUCH1o6q9vLuhK6Wy_49xGqyHvp94UYF13n9BoH"
      ],
      "metadata": {
        "id": "DNLyLbxYjt75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"./modernbert_model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./modernbert_model\")\n",
        "model.eval()\n",
        "\n",
        "label2cat = {\n",
        "    0: \"Cardiovascular / Pulmonary\",\n",
        "    1: \"ENT - Otolaryngology\",\n",
        "    2: \"Gastroenterology\",\n",
        "    3: \"Hematology - Oncology\",\n",
        "    4: \"Nephrology\",\n",
        "    5: \"Neurology\",\n",
        "    6: \"Neurosurgery\",\n",
        "    7: \"Obstetrics / Gynecology\",\n",
        "    8: \"Ophthalmology\",\n",
        "    9: \"Orthopedic\",\n",
        "    10: \"Pediatrics - Neonatal\",\n",
        "    11: \"Psychiatry / Psychology\",\n",
        "    12: \"Radiology\"\n",
        "}\n",
        "\n",
        "st.title(\"üß† Classificador M√©dico por Descri√ß√£o do Paciente\")\n",
        "st.write(\"Insira abaixo uma descri√ß√£o do paciente para prever a especialidade m√©dica correspondente.\")\n",
        "\n",
        "input_text = st.text_area(\"üìã Descri√ß√£o do paciente:\")\n",
        "\n",
        "if st.button(\"üîç Classificar\"):\n",
        "    if input_text.strip() == \"\":\n",
        "        st.warning(\"Por favor, digite uma descri√ß√£o v√°lida.\")\n",
        "    else:\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            predicted_label = torch.argmax(probs, dim=1).item()\n",
        "            confidence = probs[0][predicted_label].item()\n",
        "\n",
        "        st.success(f\"ü©∫ Especialidade prevista: **{label2cat[predicted_label]}**\")\n",
        "        st.info(f\"üî¢ Confian√ßa: {confidence:.2%}\")"
      ],
      "metadata": {
        "id": "_2DvP1ghPIa_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./modernbert_model\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./modernbert_model\")\n",
        "model.eval()\n",
        "\n",
        "label2cat = {\n",
        "    0: \"Cardiovascular / Pulmonary\",\n",
        "    1: \"ENT - Otolaryngology\",\n",
        "    2: \"Gastroenterology\",\n",
        "    3: \"Hematology - Oncology\",\n",
        "    4: \"Nephrology\",\n",
        "    5: \"Neurology\",\n",
        "    6: \"Neurosurgery\",\n",
        "    7: \"Obstetrics / Gynecology\",\n",
        "    8: \"Ophthalmology\",\n",
        "    9: \"Orthopedic\",\n",
        "    10: \"Pediatrics - Neonatal\",\n",
        "    11: \"Psychiatry / Psychology\",\n",
        "    12: \"Radiology\"\n",
        "}\n",
        "\n",
        "st.title(\"üß† Classificador M√©dico por Descri√ß√£o do Paciente\")\n",
        "st.write(\"Insira abaixo uma descri√ß√£o do paciente para prever a especialidade m√©dica correspondente.\")\n",
        "\n",
        "input_text = st.text_area(\"üìã Descri√ß√£o do paciente:\")\n",
        "\n",
        "if st.button(\"üîç Classificar\"):\n",
        "    if input_text.strip() == \"\":\n",
        "        st.warning(\"Por favor, digite uma descri√ß√£o v√°lida.\")\n",
        "    else:\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "            predicted_label = torch.argmax(probs, dim=1).item()\n",
        "            confidence = probs[0][predicted_label].item()\n",
        "\n",
        "        st.success(f\"ü©∫ Especialidade prevista: **{label2cat[predicted_label]}**\")\n",
        "        st.info(f\"üî¢ Confian√ßa: {confidence:.2%}\")\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "MTSp1l9v7PAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls app.py\n"
      ],
      "metadata": {
        "id": "68ehrd5962Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill streamlit || true\n",
        "!streamlit run app.py &> streamlit.log &\n"
      ],
      "metadata": {
        "id": "O_AX0yBzgcuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Aguarda o app iniciar\n",
        "time.sleep(5)\n",
        "\n",
        "# Cria o t√∫nel na porta 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"‚úÖ App dispon√≠vel em: {public_url}\")\n"
      ],
      "metadata": {
        "id": "6hwXO5Mw6VeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import autotokenizer, automodelforsequenceclassification"
      ],
      "metadata": {
        "id": "xdEi0Ao99mlm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}